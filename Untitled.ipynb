{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       train\n",
    "people_tr = pd.read_csv('../dataset/train.csv')\n",
    "train_labels = pd.read_csv('../dataset/train_labels.csv')\n",
    "people_tr_size = len(train_labels)\n",
    "#       test\n",
    "people_tst = pd.read_csv('../dataset/test.csv')\n",
    "test_labels = pd.read_csv('../dataset/test_labels.csv')\n",
    "people_tst_size = len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       drop id and name\n",
    "people_tr = people_tr.drop(['PassengerId', 'Name'], axis=1)\n",
    "people_tst = people_tst.drop(['PassengerId', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#       Sex to boolean\n",
    "people_tr['Sex'] = people_tr['Sex'].replace('female', 0)\n",
    "people_tr['Sex'] = people_tr['Sex'].replace('male', 1)\n",
    "people_tst['Sex'] = people_tst['Sex'].replace('female', 0)\n",
    "people_tst['Sex'] = people_tst['Sex'].replace('male', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        one hot encoder for cabin embarked\n",
    "#          embarked train\n",
    "embarked_tr = people_tr['Embarked'].values.reshape(people_tr_size, 1).tolist()\n",
    "embarked_tst = people_tst['Embarked'].values.reshape(people_tst_size, 1).tolist()\n",
    "embarked_tr.extend(embarked_tst)\n",
    "\n",
    "en = OneHotEncoder().fit(embarked_tr)\n",
    "embarked_tr = en.transform(embarked_tr[:people_tr_size]).toarray()\n",
    "people_tr['Embarked_first'] = embarked_tr[:, 0]\n",
    "people_tr['Embarked_second'] = embarked_tr[:, 1]\n",
    "people_tr['Embarked_third'] = embarked_tr[:, 2]\n",
    "people_tr = people_tr.drop('Embarked', axis=1)\n",
    "\n",
    "#          embarked test\n",
    "\n",
    "embarked_tst = en.transform(embarked_tst).toarray()\n",
    "people_tst['Embarked_first'] = embarked_tst[:, 0]\n",
    "people_tst['Embarked_second'] = embarked_tst[:, 1]\n",
    "people_tst['Embarked_third'] = embarked_tst[:, 2]\n",
    "people_tst = people_tst.drop('Embarked', axis=1)\n",
    "\n",
    "#          cabin train\n",
    "Cabin_tr = people_tr['Cabin'].values.reshape(people_tr_size, 1).tolist()\n",
    "Cabin_tst = people_tst['Cabin'].values.reshape(people_tst_size, 1).tolist()\n",
    "Cabin_tr.extend(Cabin_tst)\n",
    "\n",
    "en = OneHotEncoder().fit(Cabin_tr)\n",
    "Cabin_tr = en.transform(Cabin_tr[:people_tr_size]).toarray()\n",
    "people_tr['Cabin_first'] = Cabin_tr[:, 0]\n",
    "people_tr['Cabin_second'] = Cabin_tr[:, 1]\n",
    "people_tr['Cabin_third'] = Cabin_tr[:, 2]\n",
    "people_tr = people_tr.drop('Cabin', axis=1)\n",
    "\n",
    "#          cabin test\n",
    "Cabin_tst = en.transform(Cabin_tst).toarray()\n",
    "people_tst['Cabin_first'] = Cabin_tst[:, 0]\n",
    "people_tst['Cabin_second'] = Cabin_tst[:, 1]\n",
    "people_tst['Cabin_third'] = Cabin_tst[:, 2]\n",
    "people_tst = people_tst.drop('Cabin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan values\n",
    "mod = people_tr.mode().iloc[0]\n",
    "people_tr = people_tr.fillna(mod,)\n",
    "people_tst = people_tst.fillna(mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to list\n",
    "\n",
    "X_train = people_tr.values.tolist()\n",
    "Y_train = train_labels['Survived'].tolist()\n",
    "\n",
    "X_test = people_tst.values.tolist()\n",
    "Y_test = test_labels['Survived'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model\n",
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=40,max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit model\n",
    "clf = clf.fit(np.array(X_train, dtype=np.float32), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree accuracy on train : 0.78875\n",
      "decision tree accuracy on test : 0.7692307692307693\n"
     ]
    }
   ],
   "source": [
    "## predict\n",
    "predict_TestOrTrain = \"both\"\n",
    "if predict_TestOrTrain == \"test\":\n",
    "    # compute accuracy train\n",
    "    predicts = clf.predict(np.array(X_train, dtype=np.float32))\n",
    "    matched = 0\n",
    "    for i in range(len(predicts)):\n",
    "        if predicts[i] == Y_train[i]:\n",
    "            matched += 1\n",
    "    print(\"decision tree accuracy on test : \" + str(matched / len(Y_train)))\n",
    "elif predict_TestOrTrain == \"train\":\n",
    "    # compute accuracy test\n",
    "    predicts = clf.predict(np.array(X_test, dtype=np.float32))\n",
    "    matched = 0\n",
    "    for i in range(len(predicts)):\n",
    "        if predicts[i] == Y_test[i]:\n",
    "            matched += 1\n",
    "    print(\"decision tree accuracy on train : \" + str(matched / len(Y_test)))\n",
    "else:\n",
    "    # compute accuracy train\n",
    "    predicts = clf.predict(np.array(X_train, dtype=np.float32))\n",
    "    matched = 0\n",
    "    for i in range(len(predicts)):\n",
    "        if predicts[i] == Y_train[i]:\n",
    "            matched += 1\n",
    "    print(\"decision tree accuracy on train : \" + str(matched / len(Y_train)))\n",
    "    # compute accuracy test\n",
    "    predicts = clf.predict(np.array(X_test, dtype=np.float32))\n",
    "    matched = 0\n",
    "    for i in range(len(predicts)):\n",
    "        if predicts[i] == Y_test[i]:\n",
    "            matched += 1\n",
    "    print(\"decision tree accuracy on test : \" + str(matched / len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20, 10))\n",
    "# tree.plot_tree(clf, fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perceptron accuracy on train : 0.69625\n",
      "perceptron accuracy on test : 0.8021978021978022\n"
     ]
    }
   ],
   "source": [
    "s_Scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = s_Scaler.transform(X_train)\n",
    "X_test = s_Scaler.transform(X_test)\n",
    "# clf = Perceptron(tol=1e-5, random_state=1, shuffle=True, n_iter_no_change=10)\n",
    "perc_clf = Perceptron(tol=1e-5, random_state=0)\n",
    "perc_clf.fit(X_train, Y_train)\n",
    "print(\"perceptron accuracy on train : \" + str(perc_clf.score(X_train, Y_train)))\n",
    "print(\"perceptron accuracy on test : \" + str(perc_clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex', 'Embarked_third', 'Cabin_first', 'Cabin_second', 'Cabin_third'], dtype='object')\n",
      "with feature selection : \n",
      "perceptron accuracy on train : 0.69625\n",
      "perceptron accuracy on test : 0.8021978021978022\n"
     ]
    }
   ],
   "source": [
    "# select good features\n",
    "all_features = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
    "good_features = set(clf.feature_importances_.argsort()[-5:])\n",
    "bad_features = list(all_features.difference(good_features))\n",
    "\n",
    "features_name = people_tr.columns\n",
    "for i in bad_features:\n",
    "    people_tr = people_tr.drop(features_name[i], axis=1)\n",
    "    people_tst = people_tst.drop(features_name[i], axis=1)\n",
    "print(people_tr.columns)\n",
    "X_train = people_tr.values.tolist()\n",
    "Y_train = train_labels['Survived'].tolist()\n",
    "\n",
    "X_test = people_tst.values.tolist()\n",
    "Y_test = test_labels['Survived'].tolist()\n",
    "\n",
    "s_Scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = s_Scaler.transform(X_train)\n",
    "X_test = s_Scaler.transform(X_test)\n",
    "# clf = Perceptron(tol=1e-5, random_state=1, shuffle=True, n_iter_no_change=10)\n",
    "clf = Perceptron(tol=1e-5, random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"with feature selection : \")\n",
    "print(\"perceptron accuracy on train : \" + str(clf.score(X_train, Y_train)))\n",
    "print(\"perceptron accuracy on test : \" + str(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
